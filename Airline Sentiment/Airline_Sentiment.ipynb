{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "765f2508",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import time\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem.lancaster import LancasterStemmer\n",
    "from nltk.corpus import wordnet as wn\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "83fc0698",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in c:\\softwares\\anacondas\\lib\\site-packages (1.0.2)\n",
      "Requirement already satisfied: scipy>=1.1.0 in c:\\softwares\\anacondas\\lib\\site-packages (from scikit-learn) (1.7.3)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\softwares\\anacondas\\lib\\site-packages (from scikit-learn) (1.1.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\softwares\\anacondas\\lib\\site-packages (from scikit-learn) (2.2.0)\n",
      "Requirement already satisfied: numpy>=1.14.6 in c:\\softwares\\anacondas\\lib\\site-packages (from scikit-learn) (1.21.5)\n"
     ]
    }
   ],
   "source": [
    "!pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0f8d6f2d",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name '_OneToOneFeatureMixin' from 'sklearn.base' (C:\\Softwares\\AnacondaS\\lib\\site-packages\\sklearn\\base.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Input \u001b[1;32mIn [4]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_selection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m train_test_split\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfeature_extraction\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtext\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m TfidfVectorizer\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlinear_model\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LogisticRegression\n",
      "File \u001b[1;32mC:\\Softwares\\AnacondaS\\lib\\site-packages\\sklearn\\model_selection\\__init__.py:23\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_split\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m train_test_split\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_split\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m check_cv\n\u001b[1;32m---> 23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_validation\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m cross_val_score\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_validation\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m cross_val_predict\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_validation\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m cross_validate\n",
      "File \u001b[1;32mC:\\Softwares\\AnacondaS\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:31\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfixes\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m delayed\n\u001b[0;32m     30\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetaestimators\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _safe_split\n\u001b[1;32m---> 31\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m check_scoring\n\u001b[0;32m     32\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_scorer\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _check_multimetric_scoring, _MultimetricScorer\n\u001b[0;32m     33\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexceptions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m FitFailedWarning, NotFittedError\n",
      "File \u001b[1;32mC:\\Softwares\\AnacondaS\\lib\\site-packages\\sklearn\\metrics\\__init__.py:7\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;124;03mThe :mod:`sklearn.metrics` module includes score functions, performance metrics\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;124;03mand pairwise metrics and distance computations.\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_ranking\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m auc\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_ranking\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m average_precision_score\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_ranking\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m coverage_error\n",
      "File \u001b[1;32mC:\\Softwares\\AnacondaS\\lib\\site-packages\\sklearn\\metrics\\_ranking.py:37\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msparsefuncs\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m count_nonzero\n\u001b[0;32m     36\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexceptions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m UndefinedMetricWarning\n\u001b[1;32m---> 37\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpreprocessing\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m label_binarize\n\u001b[0;32m     38\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_encode\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _encode, _unique\n\u001b[0;32m     40\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_base\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     41\u001b[0m     _average_binary_score,\n\u001b[0;32m     42\u001b[0m     _average_multiclass_ovo_score,\n\u001b[0;32m     43\u001b[0m     _check_pos_label_consistency,\n\u001b[0;32m     44\u001b[0m )\n",
      "File \u001b[1;32mC:\\Softwares\\AnacondaS\\lib\\site-packages\\sklearn\\preprocessing\\__init__.py:8\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;124;03mThe :mod:`sklearn.preprocessing` module includes scaling, centering,\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;124;03mnormalization, binarization methods.\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_function_transformer\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m FunctionTransformer\n\u001b[1;32m----> 8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_data\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Binarizer\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_data\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m KernelCenterer\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_data\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m MinMaxScaler\n",
      "File \u001b[1;32mC:\\Softwares\\AnacondaS\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:19\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m optimize\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mspecial\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m boxcox\n\u001b[1;32m---> 19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BaseEstimator, TransformerMixin, _OneToOneFeatureMixin\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m check_array\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdeprecation\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m deprecated\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name '_OneToOneFeatureMixin' from 'sklearn.base' (C:\\Softwares\\AnacondaS\\lib\\site-packages\\sklearn\\base.py)"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import xgboost as xgb\n",
    "from sklearn import svm\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn import tree\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe1ee156",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"C:/Users/jpadmanabhan/Downloads/Tweets.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b57b663c",
   "metadata": {},
   "outputs": [],
   "source": [
    "(len(df) - df.count())/len(df) #To get % of missing val. if any col has >90%, drop them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "925a9769",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.retweet_count.sort_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3a892c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(['airline_sentiment_gold','negativereason_gold','tweet_coord'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6bd0746",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_count = df['airline_sentiment'].value_counts()\n",
    "sentiment_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b05469b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Graphical representation of airline sentiment\n",
    "sns.countplot(x='airline_sentiment',data=df,order=['negative','neutral','positive'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7978631a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.catplot(x = 'airline_sentiment',data=df,\n",
    "               order = ['negative','neutral','positive'],\n",
    "               kind = 'count',col_wrap=3,col='airline',\n",
    "               height=4,aspect=0.6,sharex=False,sharey=False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50981642",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['negativereason'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a605522",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Graphical representation of negativereason towards airlines\n",
    "sns.catplot(x = 'airline',data = df,kind = 'count',hue='negativereason',height=12,aspect=.9)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6c44e7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.catplot(x = 'negativereason',data=df,kind='count',col='airline',height=9,aspect=.8,col_wrap=2,sharex=False,sharey=False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e90b8a60",
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "#remove words which starts with @ symbols, * is for checking if the char starts with the specified val.\n",
    "df['text'] = df['text'].map(lambda x:re.sub('@\\w*','',str(x)))\n",
    "#remove special characters except [a-zA-Z]\n",
    "df['text'] = df['text'].map(lambda x:re.sub('[^a-zA-Z]',' ',str(x)))\n",
    "#remove link starts with https\n",
    "df['text'] = df['text'].map(lambda x:re.sub('http.*','',str(x)))\n",
    "end = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1af33363",
   "metadata": {},
   "outputs": [],
   "source": [
    "#To find total time consume to filter data\n",
    "end - start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61ede55c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa304d06",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Converting all text to lowercase because lowercase and uppercase char have differeny ascii nos.\n",
    "df['text'] = df['text'].map(lambda x:str(x).lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b4c91aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dee5d670",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove stopwords from comments such as 'the', 'a', 'an', 'in', etc\n",
    "# Not used PorterStemmer to make words pure\n",
    "corpus = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20fc8857",
   "metadata": {},
   "outputs": [],
   "source": [
    "sw_none = df['text'].map(lambda x:corpus.append(' '.join([word for word in str(x).strip().split() \n",
    "                                                          if not word in set(stopwords.words('english'))])))\n",
    "sw_none"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cbeda02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run for better understanding of the logic\n",
    "for word in str(df['text']).strip().split():\n",
    "    if not word in set(stopwords.words('english')):\n",
    "        print(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3a5591b",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77aa3c73",
   "metadata": {},
   "outputs": [],
   "source": [
    "ps = PorterStemmer()\n",
    "  \n",
    "#sentence = \"Programmers program with programming languages\"\n",
    "#words = word_tokenize(sentence)\n",
    "stem_corpus = []\n",
    "stem_corpus1 = []\n",
    "for w in corpus:\n",
    "    stem_corpus = stem_corpus1.append(ps.stem(w))\n",
    "    #stem_corpus.append(ps.stem(w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "898b869c",
   "metadata": {},
   "outputs": [],
   "source": [
    "st = LancasterStemmer()\n",
    "\n",
    "stem_corpus = []\n",
    "stem_corpus1 = []\n",
    "for w in corpus:\n",
    "    stem_corpus = stem_corpus1.append(st.stem(w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7813d850",
   "metadata": {},
   "outputs": [],
   "source": [
    "stem_corpus1[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4359111a",
   "metadata": {},
   "source": [
    "### Training and Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0373aac",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = pd.DataFrame(data=corpus,columns=['new_text'])\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e90e030",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['airline_sentiment'].map({'neutral':1,'negative':0,'positive':2})\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38d02af1",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "315af07c",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train.shape, x_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b2d608a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use TfidfVectorizer for feature extraction\n",
    "#token_patten #2 for word length greater than 2>=\n",
    "vector = TfidfVectorizer(stop_words='english', sublinear_tf=True,strip_accents='ascii',\n",
    "                         analyzer='word',token_pattern=r'\\w{2,}',ngram_range=(1,1),max_features=30000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b6ebea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_word_feature = vector.fit_transform(x_train['new_text']).toarray()\n",
    "x_test_word_feature = vector.transform(x_test['new_text']).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9179e268",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_word_feature.shape, x_test_word_feature.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9ea1aa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression(max_iter=10000)\n",
    "lr.fit(x_train_word_feature,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a96f9dbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predlr = lr.predict(x_test_word_feature)\n",
    "accuracy = accuracy_score(y_test,y_predlr)\n",
    "accuracy\n",
    "#0.7687841530054644"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "683f7e5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_test,y_predlr)\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ff9d038",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test,y_predlr),'\\n',accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ba03e52",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_prob = lr.predict_proba(x_train_word_feature) #Predict gives 0 or 1 as o/p, Predict_proba gives prob. of both 0 and 1.\n",
    "y_pred_prob[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6ec9f1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc = RandomForestClassifier(max_depth=3, random_state=0)\n",
    "rfc.fit(x_train_word_feature,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa773bf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predrfc = rfc.predict(x_test_word_feature)\n",
    "accuracy = accuracy_score(y_test,y_predrfc)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59008500",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test,y_predrfc),'\\n',accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bac4b15",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb1 = xgb.XGBClassifier(learning_rate=0.30009999, max_depth=5)\n",
    "xgb1.fit(x_train_word_feature, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7b1c431",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predxgb = xgb1.predict(x_test_word_feature)\n",
    "accuracy = accuracy_score(y_test,y_predxgb)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad450883",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test,y_predxgb),'\\n',accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "534e01c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "gnb = GaussianNB()\n",
    "gnb.fit(x_train_word_feature, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c63163c",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predgnb = gnb.predict(x_test_word_feature)\n",
    "accuracy = accuracy_score(y_test,y_predgnb)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7843c642",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test,y_predgnb),'\\n',accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d1e6156",
   "metadata": {},
   "outputs": [],
   "source": [
    "svm1 = svm.SVC()\n",
    "svm1.fit(x_train_word_feature, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bc335b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predsvm = svm1.predict(x_test_word_feature)\n",
    "accuracy = accuracy_score(y_test,y_predsvm)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6e8746b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test,y_predsvm),'\\n',accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd2d4ffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtc = tree.DecisionTreeClassifier()\n",
    "dtc.fit(x_train_word_feature, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbc478e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_preddtc = dtc.predict(x_test_word_feature)\n",
    "accuracy = accuracy_score(y_test,y_preddtc)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28f0b7ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test,y_preddtc),'\\n',accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8b472ec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de2466bc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
